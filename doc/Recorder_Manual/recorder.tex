\documentclass[a4paper]{article}
\title{Development Manual}
\begin{document}
\author{ Cliff Swafford, John Hughes, Satyaraj Ryali}
\maketitle
\section{Recorder Program Flow}
\begin{enumerate}
\item \textbf{Build A/V container}
	\\Initialize the container for all our A/V encoding to be written to.
	\begin{enumerate}
		\item Using \fbox{av\_guess\_format}, our program attempts to guess the audio and video codec based off of the file input. 				
				With the format received from recorder, we build the format container using \fbox{avformat\_alloc\_context}. 
				Then, we open the container for use with the recorder. \\\textit{Note:} We only handle the mkv container.
		\item Now that we have the codec type required for our containers, we can intialize the audio and video streams. Our audio and video streams configured for \textbf{Mpeg4} video encoding and \textbf{MP2} audio encoding, respectively.
	\end{enumerate}
\item \textbf{Camera Initialization}
	\\Open up file descriptors to the webcam for video and audio recording. Initialize formats for the data that we receive.
	\begin{enumerate}
		\item Using OSS, we open a file descripter to \textbf{/dev/dsp/} for audio recording. We sample	at a rate of \verb 44kHz  with \verb 16  bits per sample. Our audio encoding format is \textbf{MP2}.
		\item \fbox{video\_record\_init} Open the camera at \textbf{/dev/video} for communication. Set the format of the video frames received from the camera to be \textbf{YUY2} encoded. Initialize the width and height of the frame to \textbf{640} by \textbf{480}.
		\item Since the webcam doesn't enable read() access, we need to mmap the webcam frame buffers into our programs address space. Currently, we are using \textbf{10} buffer frames. Our buffer structure is shown as described below.
			\begin{verbatim}
	struct buffer {
    void * start;
    int length;
	};

	struct buffer * buffers;

			\end{verbatim}
		\item We then instruct the webcam to queue 10 buffer frames to be ready for retrieval.
		\item SDL Initialize
			\begin{itemize}
				\item In order to display the webcam's image to the screen, we use SDL to display the images we receive from the webcam buffer. The SDL window is initialized to match our image format paramters and create a \textbf{YUYOverlay} to present the frame.
				\item To allow for pan/tilt control, we listen for key presses in the SDL window. The up/down arrow keys are mapped for tilt functions and the left/right arrow keys are mapped for pan functions.
	\\\it Note: We have to wrap the pan/tilt ioctl calls in a while loop since they don't necessarily work the first time we try to control the camera.
			\end{itemize}
	\end{enumerate}
\item \textbf{Concurrent Encoding}
		\\ In order to prevent process blocking from audio and video encoding, each encoding function is spawned on its own thread. Write access to the container is proteced via mutex locks.
	\begin{enumerate}
		\item \textbf{Video Recording}
			\begin{enumerate}
				\item \fbox{video\_frame\_copy} Dequeue a frame from the webcam buffer into our buffers struct and return the index of the buffer that is available.
				\item \fbox{video\_frame\_display} Use the index of the newly available buffer and memcpy the video frame into the SDLYUY Overlay.
			\end{enumerate}
		\item \textbf{Video Encoding}	
			\begin{enumerate}
				\item Now that a frame from the webcam is now available in our program, we send it to \verb video_frame_compress  for encoding.
				\item In order for \verb* ffmepg  to encode our video frame, we need to convert it from a \verb yuyv422_frame  to a \verb yuyv420_frame .
				\item Now that our frame is converted, we build a video packet. Then we scale its presentation time stamp with codec specifications and our actual encoding rate.
				\item After the packet is intialized and filled with our frame data, it's sent to be written to the file. 
						\\\textit{Note:} This write operation is protected by a mutex to prevent concurrent writes.
			\end{enumerate}
		\item \textbf{Audio Recording}
			\\ \fbox{audio\_segment\_copy} Read one sample from the microphone.
		\item \textbf{Audio Encoding}
			\begin{enumerate}
				\item \fbox{audio\_segment\_compress} Using the sample read from the microphone, we send the data to be encoded into an audio packet. 
				\item \fbox{audio\_segment\_write} Our audio packet is then written to the container.
						\\\textit{Note:} This write operation is protected by a mutex to prevent concurrent writes.
			\end{enumerate}
	\end{enumerate}


\end{enumerate}

\section{Sources}
\begin{description}
	\item We used example usage of ffmpeg and the v4l2 api to help drive our development. The resources we used are linked here.
\end{description}
\begin{itemize}
	\item \textbf{V4l2 API:} http://v4l2spec.bytesex.org/spec/book1.htm
	\item \textbf{V4L2 Capture Example:} http://v4l2spec.bytesex.org/spec/capture-example.html
	\item \textbf{Pan/Tilt Example:} http://www.zerofsck.org/2009/03/09/example-code-pan-and-tilt-your-logitech-sphere-webcam-using-python-module-lpantilt-linux-v4l2/
	\item \textbf{FFMPEG Example:} http://recapstudio.googlecode.com/hg/src/common/AVEncoder.cpp?r=4c707b0b25c2499b86aaeb3d096e16bd7dc441a6
\end{itemize}

\end{document}

